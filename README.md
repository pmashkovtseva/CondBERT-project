# CondBERT for style transfer tasks in different domains

## [Text Detoxification using Large Pre-trained Neural Models](https://aclanthology.org/2021.emnlp-main.629/): О чем статья
Авторы предлагают два метода детоксификации для непараллельных данных: ParaGeDI и CondBERT. Оба подхода основываются на детекции характерных для исходного стиля токенов и их замене на токены целевого стиля. Мы решили проверить, насколько хорошо CondBERT справляется с задачами TST в других категориях.
## CondBert: алгоритм работы
Авторы обучили логистическую регрессию на задаче классификации токсичных текстов, использовав слова качестве признаков. Таким образом, для каждого слова они получили скор, определяющий важность данного слова при классификации.  
Для каждого токена входного предложения рассчитывается его токсичность. Если она превышает заданный порог, токен заменяется на [MASK], и BERT предсказывает новый.


Стоит также отметить следующее:
1. BERT также может предлагать токсичные токены в качестве новых, поэтому авторы рассчитали значение токсичности для каждого BERT-токена и штрафовали модель за предсказывание слов с высоким скором.
2. При помощи последовательной BeamSearch-генерации токенов модель получила возможность предсказывать несколько токенов на месте одного маскированного.
## Что решили сделать мы
Оценить эффективность предложенного авторами подхода CondBert для других текстовых доменов. Это мотивировано тем, что токсичная речь в значительной степени маркирована и характеризуется специфичной лексикой, что не всегда верно для других, менее явных стилей.
Для оценки мы выбрали следующие стили: вежливость (Politeness), юмор (Humour), нейтральность (Neutrality) и “шекспиризация” (Shakespearizing Modern English).
## Мотивация выбора метода
Результаты, полученные с помощью ParaGeDi и CondBERT для детоксификации, стали SOTA в этой задаче. Они показывают примерно одинаковые результаты при автоматическом подсчете метрик, но CondBERT быстрее и проще в имплементации. Было бы интересно посмотреть, насколько этот пайплайн применим к другим типам текстов.
## Ограничения
Существует очень мало параллельных датасетов для переноса стиля, и мы, как и авторы статьи, не могли воспользоваться более-менее традиционными метриками – BLEU, METEOR или ROGUE. Теоретически, в дальнейших исследованиях будет сложно сравнивать модели, обученные на параллельных и непараллельных данных.


[Оригинальный репозиторий](https://github.com/s-nlp/detox/tree/main/emnlp2021/style_transfer/condBERT) статьи


## Politeness
### Кто делал


Полина Черноморченко


### Датасет
[Politeness transfer dataset](https://github.com/tag-and-generate/politeness-dataset/blob/master/README.md)


### Описание результатов и метрики
Метрики:
| ACC | SIM | FL | J | BLEU |
| --- | --- | -- | - | ---- |
|0.8390|0.5901|0.0540|0.0318|0.5658|

Выводы: как и ожидалось, для пары вежливость-невежливость стратегия замены токенов работает плохо. Это обусловлено тем, что невежливость слабо выражается на лексическом уровне, поэтому замена токенов не дает ожидаемого результата. Более того, у маркеров вежливости, как правило, нет невежливой синонимической пары (трудно представить невежливое "спасибо"), поэтому в качестве "вежливых" заменяющих токенов нередко выступают служеные слова, что приводит к очень низкому уровню приемлемости.
Пример:\
Оригинал: why he said it: another way to say, "its not my fault, its their fault"\
CondBERT: so he said it: another way to say, its not my it, its their it



…

## Humour
### Кто делал


Полина Машковцева


### Датасет


[FlickrStyle](https://paperswithcode.com/dataset/flickrstyle10k)


### Описание результатов и метрики


…


## Neutrality
### Кто делал


Саша Шахнова


### Датасет


[Wiki Neutrality Corpus](http://bit.ly/bias-corpus)


### Описание результатов и метрики


…


## Shakespearizing Modern English
### Кто делал


Таня Перевощикова


### Датасет


[Shakespearify](https://www.kaggle.com/datasets/garnavaurha/shakespearify)


### Описание результатов и метрики


…
