# CondBERT for style transfer tasks in different domains

## [Text Detoxification using Large Pre-trained Neural Models](https://aclanthology.org/2021.emnlp-main.629/): О чем статья
Авторы предлагают два метода детоксификации для непараллельных данных: ParaGeDI и CondBERT. Оба подхода основываются на детекции характерных для исходного стиля токенов и их замене на токены целевого стиля. Мы решили проверить, насколько хорошо CondBERT справляется с задачами TST в других категориях.
## CondBert: алгоритм работы
Авторы обучили логистическую регрессию на задаче классификации токсичных текстов, использовав слова качестве признаков. Таким образом, для каждого слова они получили скор, определяющий важность данного слова при классификации.  
Для каждого токена входного предложения рассчитывается его токсичность. Если она превышает заданный порог, токен заменяется на [MASK], и BERT предсказывает новый.


Стоит также отметить следующее:
1. BERT также может предлагать токсичные токены в качестве новых, поэтому авторы рассчитали значение токсичности для каждого BERT-токена и штрафовали модель за предсказывание слов с высоким скором.
2. При помощи последовательной BeamSearch-генерации токенов модель получила возможность предсказывать несколько токенов на месте одного маскированного.
## Что решили сделать мы
Оценить эффективность предложенного авторами подхода CondBert для других текстовых доменов. Это мотивировано тем, что токсичная речь в значительной степени маркирована и характеризуется специфичной лексикой, что не всегда верно для других, менее явных стилей.
Для оценки мы выбрали следующие стили: вежливость (Politeness), юмор (Humour), нейтральность (Neutrality) и “шекспиризация” (Shakespearizing Modern English).
## Мотивация выбора метода
Результаты, полученные с помощью ParaGeDi и CondBERT для детоксификации, стали SOTA в этой задаче. Они показывают примерно одинаковые результаты при автоматическом подсчете метрик, но CondBERT быстрее и проще в имплементации. Было бы интересно посмотреть, насколько этот пайплайн применим к другим типам текстов.
## Ограничения
Существует очень мало параллельных датасетов для переноса стиля, и мы, как и авторы статьи, не могли воспользоваться более-менее традиционными метриками – BLEU, METEOR или ROGUE. Теоретически, в дальнейших исследованиях будет сложно сравнивать модели, обученные на параллельных и непараллельных данных.


[Оригинальный репозиторий](https://github.com/s-nlp/detox/tree/main/emnlp2021/style_transfer/condBERT) статьи


## Politeness
### Кто делал


Полина Черноморченко


### Датасет
[Politeness transfer dataset](https://github.com/tag-and-generate/politeness-dataset/blob/master/README.md)


### Описание результатов и метрики
Метрики:
| ACC | SIM | FL | J | BLEU |
| --- | --- | -- | - | ---- |
|0.9420|0.7374|0.8170|0.5768|0.6783|

Выводы:\ 
Я ожидала, что модель справиться с вежливостью хуже, чем с токсичностью, потому что невежливость менее выражена на лексическом уровне. Тем не менее, моя гипотеза не опрадалась - скор J для вежливости даже выше, чем у детоксификации. Кажется, невежливость выражается в лексическом плане не очень очевидным  (для носителя в моем лице) образом: самое "невежливое" слово  по версии логрега - "why".

Пример:\
Оригинал: why it has always failed and why it will fail again by caleb carr holy war , inc. :\
CondBERT: i know that it has always been possible , and i know that it will fail again by caleb . the end of our world history , inc . :



…

## Humour
### Кто делал


Полина Машковцева


### Датасет


[FlickrStyle](https://paperswithcode.com/dataset/flickrstyle10k)


### Описание результатов и метрики


…


## Neutrality
### Кто делал


Саша Шахнова


### Датасет


[Wiki Neutrality Corpus](http://bit.ly/bias-corpus)


### Описание результатов и метрики


…


## Shakespearizing Modern English
### Кто делал


Таня Перевощикова


### Датасет


[Shakespearify](https://www.kaggle.com/datasets/garnavaurha/shakespearify)


### Описание результатов и метрики
Метрики:
| ACC | SIM | FL | J | BLEU |
| --- | --- | -- | - | ---- |
|0.8160|0.8425|0.5130|0.3624|0.7651|
…
