{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 0. Prerequisites","metadata":{}},{"cell_type":"code","source":"!pip install gdown --quiet","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:26:50.728435Z","iopub.execute_input":"2023-03-26T10:26:50.728923Z","iopub.status.idle":"2023-03-26T10:27:03.644284Z","shell.execute_reply.started":"2023-03-26T10:26:50.728887Z","shell.execute_reply":"2023-03-26T10:27:03.642986Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom nltk import sent_tokenize, word_tokenize\nimport random\nimport os\nimport sys","metadata":{"execution":{"iopub.status.busy":"2023-03-26T11:06:55.762458Z","iopub.execute_input":"2023-03-26T11:06:55.762848Z","iopub.status.idle":"2023-03-26T11:06:55.767676Z","shell.execute_reply.started":"2023-03-26T11:06:55.762816Z","shell.execute_reply":"2023-03-26T11:06:55.766622Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"data = load_dataset('onestop_english')","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:27:51.918989Z","iopub.execute_input":"2023-03-26T10:27:51.919949Z","iopub.status.idle":"2023-03-26T10:27:53.534520Z","shell.execute_reply.started":"2023-03-26T10:27:51.919900Z","shell.execute_reply":"2023-03-26T10:27:53.533303Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f4c375bc9034bacbbf4d8c221acec4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a55171952a34db187d07cc88dbbcea2"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset onestop_english/default (download: 1.17 MiB, generated: 2.17 MiB, post-processed: Unknown size, total: 3.34 MiB) to /root/.cache/huggingface/datasets/onestop_english/default/1.1.0/6b19eec5680862ad1cf1990e98b06a98d1fa4c85f3585dc4dfab93f52b89d9cf...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd60680e20314a209d06a6a6dc7702af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/567 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset onestop_english downloaded and prepared to /root/.cache/huggingface/datasets/onestop_english/default/1.1.0/6b19eec5680862ad1cf1990e98b06a98d1fa4c85f3585dc4dfab93f52b89d9cf. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c55ab2fd91a40f1aa380e918c92501a"}},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:28:03.617634Z","iopub.execute_input":"2023-03-26T10:28:03.618019Z","iopub.status.idle":"2023-03-26T10:28:03.626093Z","shell.execute_reply.started":"2023-03-26T10:28:03.617988Z","shell.execute_reply":"2023-03-26T10:28:03.624982Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 567\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"sentences_hard = []\nsentences_simple = []\nfor i in range(len(data['train'])):\n    if data['train'][i]['label'] == 2:\n        for sentence in sent_tokenize(data['train'][i]['text']):\n            sentences_hard.append(' '.join(word_tokenize(sentence.lower())))\n    elif data['train'][i]['label'] == 0:\n        for sentence in sent_tokenize(data['train'][i]['text']):\n            sentences_simple.append(' '.join(word_tokenize(sentence.lower())))","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:28:05.574533Z","iopub.execute_input":"2023-03-26T10:28:05.575679Z","iopub.status.idle":"2023-03-26T10:28:08.326451Z","shell.execute_reply.started":"2023-03-26T10:28:05.575616Z","shell.execute_reply":"2023-03-26T10:28:08.324974Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=13BC8BDL2MkksUtqsQ1clPxcPvKWgKlO3 --quiet\n!gdown https://drive.google.com/uc?id=1zUMoJk3Jkf9wh40tRG1lSI07RDMp_l8n --quiet\n!gdown https://drive.google.com/uc?id=19uhGuMkTeV_nveGQ2rbtbitQMI0b6Xsp --quiet\n!gdown https://drive.google.com/uc?id=1bmw6wGVt5h52w3WEVVndrucEDBwws66l --quiet","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:28:11.787307Z","iopub.execute_input":"2023-03-26T10:28:11.788024Z","iopub.status.idle":"2023-03-26T10:28:18.972043Z","shell.execute_reply.started":"2023-03-26T10:28:11.787987Z","shell.execute_reply":"2023-03-26T10:28:18.970561Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def read_turkers(path):\n    with open(path, 'r') as f:\n        sentences = f.read().splitlines()\n    return sentences","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:28:18.977857Z","iopub.execute_input":"2023-03-26T10:28:18.980136Z","iopub.status.idle":"2023-03-26T10:28:18.987730Z","shell.execute_reply.started":"2023-03-26T10:28:18.980086Z","shell.execute_reply":"2023-03-26T10:28:18.986766Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"turkers_hard_one = read_turkers('/kaggle/working/test.8turkers.tok.norm.txt')\nturkers_hard_two = read_turkers('/kaggle/working/tune.8turkers.tok.norm.txt')\nturkers_simple_one = read_turkers('/kaggle/working/test.8turkers.tok.simp.txt')\nturkers_simple_two = read_turkers('/kaggle/working/tune.8turkers.tok.simp.txt')","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:28:21.408951Z","iopub.execute_input":"2023-03-26T10:28:21.409884Z","iopub.status.idle":"2023-03-26T10:28:21.419825Z","shell.execute_reply.started":"2023-03-26T10:28:21.409837Z","shell.execute_reply":"2023-03-26T10:28:21.418487Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"sentences_hard += turkers_hard_one\nsentences_hard += turkers_hard_two\nsentences_simple += turkers_simple_one\nsentences_simple += turkers_simple_two","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:28:26.089831Z","iopub.execute_input":"2023-03-26T10:28:26.091012Z","iopub.status.idle":"2023-03-26T10:28:26.096563Z","shell.execute_reply.started":"2023-03-26T10:28:26.090962Z","shell.execute_reply":"2023-03-26T10:28:26.095412Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"random.shuffle(sentences_hard)\nrandom.shuffle(sentences_simple)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:28:47.792469Z","iopub.execute_input":"2023-03-26T10:28:47.792898Z","iopub.status.idle":"2023-03-26T10:28:47.816600Z","shell.execute_reply.started":"2023-03-26T10:28:47.792861Z","shell.execute_reply":"2023-03-26T10:28:47.815675Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"sentences_hard_train = sentences_hard[1001:len(sentences_hard)]\nsentences_hard_test = sentences_hard[0:1000]\n\nsentences_simple_train = sentences_simple[1001:len(sentences_simple)]\nsentences_simple_test = sentences_simple[0:1000]","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:28:50.972956Z","iopub.execute_input":"2023-03-26T10:28:50.973572Z","iopub.status.idle":"2023-03-26T10:28:50.980205Z","shell.execute_reply.started":"2023-03-26T10:28:50.973535Z","shell.execute_reply":"2023-03-26T10:28:50.978794Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def write_to_file(sentences: list, filename: str):\n    with open(filename, 'w') as f:\n        for sentence in sentences:\n            f.write(sentence.lower() + '\\n')","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:29:02.640507Z","iopub.execute_input":"2023-03-26T10:29:02.641537Z","iopub.status.idle":"2023-03-26T10:29:02.647435Z","shell.execute_reply.started":"2023-03-26T10:29:02.641488Z","shell.execute_reply":"2023-03-26T10:29:02.646279Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"write_to_file(sentences_hard_train, 'train_hard')\nwrite_to_file(sentences_hard_test, 'test_hard')\nwrite_to_file(sentences_simple_train, 'train_simple')\nwrite_to_file(sentences_simple_test, 'test_simple')","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:29:04.915568Z","iopub.execute_input":"2023-03-26T10:29:04.916563Z","iopub.status.idle":"2023-03-26T10:29:04.942322Z","shell.execute_reply.started":"2023-03-26T10:29:04.916519Z","shell.execute_reply":"2023-03-26T10:29:04.941258Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"VOCAB_DIRNAME = 'vocabularies' ","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:29:07.625969Z","iopub.execute_input":"2023-03-26T10:29:07.626338Z","iopub.status.idle":"2023-03-26T10:29:07.631343Z","shell.execute_reply.started":"2023-03-26T10:29:07.626305Z","shell.execute_reply":"2023-03-26T10:29:07.629930Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/s-nlp/detox","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:29:12.439549Z","iopub.execute_input":"2023-03-26T10:29:12.440652Z","iopub.status.idle":"2023-03-26T10:29:15.464151Z","shell.execute_reply.started":"2023-03-26T10:29:12.440585Z","shell.execute_reply":"2023-03-26T10:29:15.462699Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Cloning into 'detox'...\nremote: Enumerating objects: 180, done.\u001b[K\nremote: Counting objects: 100% (180/180), done.\u001b[K\nremote: Compressing objects: 100% (158/158), done.\u001b[K\nremote: Total 180 (delta 50), reused 118 (delta 14), pack-reused 0\u001b[K\nReceiving objects: 100% (180/180), 17.92 MiB | 19.05 MiB/s, done.\nResolving deltas: 100% (50/50), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r detox/requirements.txt --quiet","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:29:31.816869Z","iopub.execute_input":"2023-03-26T10:29:31.818028Z","iopub.status.idle":"2023-03-26T10:30:19.217149Z","shell.execute_reply.started":"2023-03-26T10:29:31.817971Z","shell.execute_reply":"2023-03-26T10:30:19.215889Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 21.12.2 requires cupy-cuda115, which is not installed.\nvirtualenv 20.17.1 requires importlib-metadata>=4.8.3; python_version < \"3.8\", but you have importlib-metadata 3.10.1 which is incompatible.\npynndescent 0.5.8 requires importlib-metadata>=4.8.1; python_version < \"3.8\", but you have importlib-metadata 3.10.1 which is incompatible.\nmarkdown 3.4.1 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\nlightning-utilities 0.7.1 requires importlib-metadata>=4.0.0; python_version < \"3.8\", but you have importlib-metadata 3.10.1 which is incompatible.\nlibrosa 0.10.0 requires soundfile>=0.12.1, but you have soundfile 0.11.0 which is incompatible.\nibis-framework 2.1.1 requires importlib-metadata<5,>=4; python_version < \"3.8\", but you have importlib-metadata 3.10.1 which is incompatible.\ngym 0.23.1 requires importlib-metadata>=4.10.0; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\ngoogle-cloud-pubsublite 1.6.0 requires overrides<7.0.0,>=6.0.1, but you have overrides 3.1.0 which is incompatible.\ncmudict 1.0.13 requires importlib-metadata<6.0.0,>=5.1.0, but you have importlib-metadata 3.10.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"def add_sys_path(p):\n    p = os.path.abspath(p)\n    print(p)\n    if p not in sys.path:\n        sys.path.append(p)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:32:27.870238Z","iopub.execute_input":"2023-03-26T10:32:27.871213Z","iopub.status.idle":"2023-03-26T10:32:27.877269Z","shell.execute_reply.started":"2023-03-26T10:32:27.871161Z","shell.execute_reply":"2023-03-26T10:32:27.876064Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"add_sys_path('detox/emnlp2021/style_transfer/condBERT')","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:32:33.684352Z","iopub.execute_input":"2023-03-26T10:32:33.684745Z","iopub.status.idle":"2023-03-26T10:32:33.690888Z","shell.execute_reply.started":"2023-03-26T10:32:33.684689Z","shell.execute_reply":"2023-03-26T10:32:33.689674Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"/kaggle/working/detox/emnlp2021/style_transfer/condBERT\n","output_type":"stream"}]},{"cell_type":"code","source":"from condbert import CondBertRewriter\nfrom choosers import EmbeddingSimilarityChooser\nfrom multiword.masked_token_predictor_bert import MaskedTokenPredictorBert","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:32:35.328172Z","iopub.execute_input":"2023-03-26T10:32:35.328556Z","iopub.status.idle":"2023-03-26T10:32:54.234573Z","shell.execute_reply.started":"2023-03-26T10:32:35.328524Z","shell.execute_reply":"2023-03-26T10:32:54.233423Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# 1. Loading BERT","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import BertTokenizer, BertForMaskedLM\nimport numpy as np\nimport pickle\nimport os\nfrom tqdm.auto import tqdm, trange","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:32:58.241002Z","iopub.execute_input":"2023-03-26T10:32:58.241637Z","iopub.status.idle":"2023-03-26T10:32:58.250881Z","shell.execute_reply.started":"2023-03-26T10:32:58.241601Z","shell.execute_reply":"2023-03-26T10:32:58.249848Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"os.environ['CUDA_VISIBLE_DEVICES'] = '0'\ndevice = torch.device('cuda:0')\ndevice = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:19.512882Z","iopub.execute_input":"2023-03-26T10:33:19.513258Z","iopub.status.idle":"2023-03-26T10:33:19.518441Z","shell.execute_reply.started":"2023-03-26T10:33:19.513225Z","shell.execute_reply":"2023-03-26T10:33:19.517437Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model_name = 'bert-base-uncased'\ntokenizer = BertTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:22.131780Z","iopub.execute_input":"2023-03-26T10:33:22.132603Z","iopub.status.idle":"2023-03-26T10:33:24.115041Z","shell.execute_reply.started":"2023-03-26T10:33:22.132561Z","shell.execute_reply":"2023-03-26T10:33:24.114111Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74ebce05591e440f8e6ae0c58e65a400"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad30e82b5fb46f7ac78c4b4e7873d8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71c17a324edd4694a165423e40bd6c19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"851a121ed85d4977a3aa6e52ac26b440"}},"metadata":{}}]},{"cell_type":"code","source":"model = BertForMaskedLM.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:25.738395Z","iopub.execute_input":"2023-03-26T10:33:25.738791Z","iopub.status.idle":"2023-03-26T10:33:35.970064Z","shell.execute_reply.started":"2023-03-26T10:33:25.738755Z","shell.execute_reply":"2023-03-26T10:33:35.969089Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff3a8f53c21d469ca579e647f6499a15"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"model.to(device);","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:37.635998Z","iopub.execute_input":"2023-03-26T10:33:37.636954Z","iopub.status.idle":"2023-03-26T10:33:37.647825Z","shell.execute_reply.started":"2023-03-26T10:33:37.636901Z","shell.execute_reply":"2023-03-26T10:33:37.646844Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# 2. Preparing the vocabularires.","metadata":{}},{"cell_type":"code","source":"hard_corpus_path = '/kaggle/working/train_hard'\nsimple_corpus_path = '/kaggle/working/train_simple'","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:39.900905Z","iopub.execute_input":"2023-03-26T10:33:39.901997Z","iopub.status.idle":"2023-03-26T10:33:39.907402Z","shell.execute_reply.started":"2023-03-26T10:33:39.901946Z","shell.execute_reply":"2023-03-26T10:33:39.906045Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(VOCAB_DIRNAME):\n    os.makedirs(VOCAB_DIRNAME)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:41.726114Z","iopub.execute_input":"2023-03-26T10:33:41.727127Z","iopub.status.idle":"2023-03-26T10:33:41.732905Z","shell.execute_reply.started":"2023-03-26T10:33:41.727080Z","shell.execute_reply":"2023-03-26T10:33:41.731544Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### 2.1 Preparing the DRG-like vocabularies","metadata":{}},{"cell_type":"code","source":"import argparse\nfrom nltk import ngrams\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\n\n\nclass NgramSalienceCalculator():\n    def __init__(self, hard_corpus, simple_corpus, use_ngrams=False):\n        ngrams = (1, 3) if use_ngrams else (1, 1)\n        self.vectorizer = CountVectorizer(ngram_range=ngrams)\n\n        hard_count_matrix = self.vectorizer.fit_transform(hard_corpus)\n        self.hard_vocab = self.vectorizer.vocabulary_\n        self.hard_counts = np.sum(hard_count_matrix, axis=0)\n\n        simple_count_matrix = self.vectorizer.fit_transform(simple_corpus)\n        self.simple_vocab = self.vectorizer.vocabulary_\n        self.simple_counts = np.sum(simple_count_matrix, axis=0)\n\n    def salience(self, feature, attribute='hard', lmbda=0.5):\n        assert attribute in ['hard', 'simple']\n        if feature not in self.hard_vocab:\n            hard_count = 0.0\n        else:\n            hard_count = self.hard_counts[0, self.hard_vocab[feature]]\n\n        if feature not in self.simple_vocab:\n            simple_count = 0.0\n        else:\n            simple_count = self.simple_counts[0, self.simple_vocab[feature]]\n\n        if attribute == 'hard':\n            return (hard_count + lmbda) / (simple_count + lmbda)\n        else:\n            return (simple_count + lmbda) / (hard_count + lmbda)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T11:07:30.883201Z","iopub.execute_input":"2023-03-26T11:07:30.883633Z","iopub.status.idle":"2023-03-26T11:07:30.902111Z","shell.execute_reply.started":"2023-03-26T11:07:30.883591Z","shell.execute_reply":"2023-03-26T11:07:30.900776Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nc = Counter()\n\nfor fn in [hard_corpus_path, simple_corpus_path]:\n    with open(fn, 'r') as corpus:\n        for line in corpus.readlines():\n            for tok in line.strip().split():\n                c[tok] += 1\n\nprint(len(c))","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:44.365485Z","iopub.execute_input":"2023-03-26T10:33:44.367008Z","iopub.status.idle":"2023-03-26T10:33:44.528039Z","shell.execute_reply.started":"2023-03-26T10:33:44.366959Z","shell.execute_reply":"2023-03-26T10:33:44.526859Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"22673\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab = {w for w, _ in c.most_common() if _ > 0}  # if we took words with > 1 occurences, vocabulary would be x2 smaller, but we'll survive this size\nprint(len(vocab))","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:46.395683Z","iopub.execute_input":"2023-03-26T10:33:46.396854Z","iopub.status.idle":"2023-03-26T10:33:46.435320Z","shell.execute_reply.started":"2023-03-26T10:33:46.396808Z","shell.execute_reply":"2023-03-26T10:33:46.434126Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"22673\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(hard_corpus_path, 'r') as hard_corpus, open(simple_corpus_path, 'r') as simple_corpus:\n    corpus_hard = [' '.join([w if w in vocab else '<unk>' for w in line.strip().split()]) for line in hard_corpus.readlines()]\n    corpus_simple = [' '.join([w if w in vocab else '<unk>' for w in line.strip().split()]) for line in simple_corpus.readlines()]","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:50.590004Z","iopub.execute_input":"2023-03-26T10:33:50.591372Z","iopub.status.idle":"2023-03-26T10:33:50.704249Z","shell.execute_reply.started":"2023-03-26T10:33:50.591319Z","shell.execute_reply":"2023-03-26T10:33:50.703125Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"hard_out_name = VOCAB_DIRNAME + '/hard-words.txt'\nsimple_out_name = VOCAB_DIRNAME + '/simple-words.txt'","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:52.118088Z","iopub.execute_input":"2023-03-26T10:33:52.119084Z","iopub.status.idle":"2023-03-26T10:33:52.124371Z","shell.execute_reply.started":"2023-03-26T10:33:52.119036Z","shell.execute_reply":"2023-03-26T10:33:52.123453Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"threshold = 1","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:54.008670Z","iopub.execute_input":"2023-03-26T10:33:54.009625Z","iopub.status.idle":"2023-03-26T10:33:54.014986Z","shell.execute_reply.started":"2023-03-26T10:33:54.009561Z","shell.execute_reply":"2023-03-26T10:33:54.013740Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"sc = NgramSalienceCalculator(corpus_hard, corpus_simple, False)\nseen_grams = set()\n\nwith open(hard_out_name, 'w') as hard_out, open(simple_out_name, 'w') as simple_out:\n    for gram in set(sc.hard_vocab.keys()).union(set(sc.simple_vocab.keys())):\n        if gram not in seen_grams:\n            seen_grams.add(gram)\n            hard_salience = sc.salience(gram, attribute='hard')\n            simple_salience = sc.salience(gram, attribute='simple')\n            if hard_salience > threshold:\n                hard_out.writelines(f'{gram}\\n')\n            elif simple_salience > threshold:\n                simple_out.writelines(f'{gram}\\n')","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:54.984940Z","iopub.execute_input":"2023-03-26T10:33:54.985895Z","iopub.status.idle":"2023-03-26T10:33:55.566752Z","shell.execute_reply.started":"2023-03-26T10:33:54.985842Z","shell.execute_reply":"2023-03-26T10:33:55.565694Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Evaluating word hardness with a logistic regression","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\npipe = make_pipeline(CountVectorizer(), LogisticRegression(max_iter=1000))","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:33:59.858505Z","iopub.execute_input":"2023-03-26T10:33:59.858933Z","iopub.status.idle":"2023-03-26T10:33:59.881639Z","shell.execute_reply.started":"2023-03-26T10:33:59.858897Z","shell.execute_reply":"2023-03-26T10:33:59.879824Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"X_train = corpus_hard + corpus_simple\ny_train = [1] * len(corpus_hard) + [0] * len(corpus_simple)\npipe.fit(X_train, y_train);","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:34:01.285099Z","iopub.execute_input":"2023-03-26T10:34:01.286062Z","iopub.status.idle":"2023-03-26T10:34:03.630642Z","shell.execute_reply.started":"2023-03-26T10:34:01.286008Z","shell.execute_reply":"2023-03-26T10:34:03.629188Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"coefs = pipe[1].coef_[0]\ncoefs.shape","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:34:05.850281Z","iopub.execute_input":"2023-03-26T10:34:05.851256Z","iopub.status.idle":"2023-03-26T10:34:05.859894Z","shell.execute_reply.started":"2023-03-26T10:34:05.851203Z","shell.execute_reply":"2023-03-26T10:34:05.858718Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"(20502,)"},"metadata":{}}]},{"cell_type":"code","source":"word2coef = {w: coefs[idx] for w, idx in pipe[0].vocabulary_.items()}","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:34:07.727656Z","iopub.execute_input":"2023-03-26T10:34:07.728377Z","iopub.status.idle":"2023-03-26T10:34:07.742087Z","shell.execute_reply.started":"2023-03-26T10:34:07.728339Z","shell.execute_reply":"2023-03-26T10:34:07.740870Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open(VOCAB_DIRNAME + '/word2coef.pkl', 'wb') as f:\n    pickle.dump(word2coef, f)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:34:10.548755Z","iopub.execute_input":"2023-03-26T10:34:10.549437Z","iopub.status.idle":"2023-03-26T10:34:10.601031Z","shell.execute_reply.started":"2023-03-26T10:34:10.549401Z","shell.execute_reply":"2023-03-26T10:34:10.600069Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Labelling BERT tokens by toxicity","metadata":{}},{"cell_type":"code","source":"from collections import defaultdict\nhard_counter = defaultdict(lambda: 1)\nsimple_counter = defaultdict(lambda: 1)\n\nfor text in tqdm(corpus_hard):\n    for token in tokenizer.encode(text):\n        hard_counter[token] += 1\nfor text in tqdm(corpus_simple):\n    for token in tokenizer.encode(text):\n        simple_counter[token] += 1","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:34:26.199702Z","iopub.execute_input":"2023-03-26T10:34:26.200669Z","iopub.status.idle":"2023-03-26T10:34:37.754135Z","shell.execute_reply.started":"2023-03-26T10:34:26.200617Z","shell.execute_reply":"2023-03-26T10:34:37.752955Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"100%|██████████| 7889/7889 [00:06<00:00, 1179.60it/s]\n100%|██████████| 6938/6938 [00:04<00:00, 1430.44it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"token_hardness = [hard_counter[i] / (simple_counter[i] + hard_counter[i]) for i in range(len(tokenizer.vocab))]","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:35:58.366466Z","iopub.execute_input":"2023-03-26T10:35:58.366949Z","iopub.status.idle":"2023-03-26T10:35:58.389252Z","shell.execute_reply.started":"2023-03-26T10:35:58.366913Z","shell.execute_reply":"2023-03-26T10:35:58.388282Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"with open(VOCAB_DIRNAME + '/token_hardness.txt', 'w') as f:\n    for t in token_hardness:\n        f.write(str(t))\n        f.write('\\n')","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:35:59.523599Z","iopub.execute_input":"2023-03-26T10:35:59.524276Z","iopub.status.idle":"2023-03-26T10:35:59.560313Z","shell.execute_reply.started":"2023-03-26T10:35:59.524243Z","shell.execute_reply":"2023-03-26T10:35:59.559324Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"# 3. Setting up the model","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Loading the vocabularies","metadata":{}},{"cell_type":"code","source":"with open(VOCAB_DIRNAME + \"/hard-words.txt\", \"r\") as f:\n    s = f.readlines()\nhard_words = list(map(lambda x: x[:-1], s))\n\nwith open(VOCAB_DIRNAME + \"/simple-words.txt\", \"r\") as f:\n    s = f.readlines()\nsimple_words = list(map(lambda x: x[:-1], s))","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:36:05.077238Z","iopub.execute_input":"2023-03-26T10:36:05.078171Z","iopub.status.idle":"2023-03-26T10:36:05.091825Z","shell.execute_reply.started":"2023-03-26T10:36:05.078119Z","shell.execute_reply":"2023-03-26T10:36:05.090780Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open(VOCAB_DIRNAME + '/word2coef.pkl', 'rb') as f:\n    word2coef = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:36:07.224655Z","iopub.execute_input":"2023-03-26T10:36:07.225354Z","iopub.status.idle":"2023-03-26T10:36:07.252823Z","shell.execute_reply.started":"2023-03-26T10:36:07.225319Z","shell.execute_reply":"2023-03-26T10:36:07.251831Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"token_hardness = []\nwith open(VOCAB_DIRNAME + '/token_hardness.txt', 'r') as f:\n    for line in f.readlines():\n        token_hardness.append(float(line))\ntoken_hardness = np.array(token_hardness)\ntoken_hardness = np.maximum(0, np.log(1/(1/token_hardness-1)))   # log odds ratio\n\n# discourage meaningless tokens\nfor tok in ['.', ',', '-']:\n    token_hardness[tokenizer.encode(tok)][1] = 3\n\nfor tok in ['you']:\n    token_hardness[tokenizer.encode(tok)][1] = 0","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:36:09.190944Z","iopub.execute_input":"2023-03-26T10:36:09.191875Z","iopub.status.idle":"2023-03-26T10:36:09.217943Z","shell.execute_reply.started":"2023-03-26T10:36:09.191826Z","shell.execute_reply":"2023-03-26T10:36:09.216998Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def adjust_logits(logits, label=0):\n    return logits - token_hardness * 100 * (1 - 2 * label)\n\npredictor = MaskedTokenPredictorBert(model, tokenizer, max_len=250, device=device, label=0, contrast_penalty=0.0, logits_postprocessor=adjust_logits)\n\neditor = CondBertRewriter(\n    model=model,\n    tokenizer=tokenizer,\n    device=device,\n    neg_words=hard_words,\n    pos_words=simple_words,\n    word2coef=word2coef,\n    token_toxicities=token_hardness,\n    predictor=predictor,\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:36:11.753582Z","iopub.execute_input":"2023-03-26T10:36:11.754264Z","iopub.status.idle":"2023-03-26T10:36:14.027680Z","shell.execute_reply.started":"2023-03-26T10:36:11.754227Z","shell.execute_reply":"2023-03-26T10:36:14.026693Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"chooser = EmbeddingSimilarityChooser(sim_coef=10, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:36:16.714512Z","iopub.execute_input":"2023-03-26T10:36:16.715195Z","iopub.status.idle":"2023-03-26T10:36:33.571607Z","shell.execute_reply.started":"2023-03-26T10:36:16.715156Z","shell.execute_reply":"2023-03-26T10:36:33.570580Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"2023-03-26 10:36:17,359 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /tmp/tmplaajkwog\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 160000128/160000128 [00:08<00:00, 19994735.82B/s]","output_type":"stream"},{"name":"stdout","text":"2023-03-26 10:36:25,766 copying /tmp/tmplaajkwog to cache at /root/.flair/embeddings/glove.gensim.vectors.npy\n2023-03-26 10:36:25,944 removing temp file /tmp/tmplaajkwog\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"name":"stdout","text":"2023-03-26 10:36:26,495 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /tmp/tmph0wofe3t\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21494764/21494764 [00:01<00:00, 12241780.88B/s]","output_type":"stream"},{"name":"stdout","text":"2023-03-26 10:36:28,673 copying /tmp/tmph0wofe3t to cache at /root/.flair/embeddings/glove.gensim\n2023-03-26 10:36:28,707 removing temp file /tmp/tmph0wofe3t\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"print(editor.translate('so social media, which can open you up to the scrutiny and analysis of others, is not that appealing to her.', prnt=False))","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:36:42.528122Z","iopub.execute_input":"2023-03-26T10:36:42.529107Z","iopub.status.idle":"2023-03-26T10:36:42.925967Z","shell.execute_reply.started":"2023-03-26T10:36:42.529054Z","shell.execute_reply":"2023-03-26T10:36:42.924782Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"so webmedia , which can open you about to the observation and observation of others , is not that attractive to her .\n","output_type":"stream"}]},{"cell_type":"code","source":"print(editor.replacement_loop('so social media, which can open you up to the scrutiny and analysis of others, is not that appealing to her.', verbose=False, chooser=chooser, n_tokens=(1, 2, 3), n_top=10))","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:36:49.360086Z","iopub.execute_input":"2023-03-26T10:36:49.361024Z","iopub.status.idle":"2023-03-26T10:38:56.343259Z","shell.execute_reply.started":"2023-03-26T10:36:49.360974Z","shell.execute_reply":"2023-03-26T10:38:56.342060Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"but studying different information information , because they do not opens many things because they respond more quickly too quickly because they make judgment mistakes because they analyze too many different things , does not make someone more interesting because they study many things .\n","output_type":"stream"}]},{"cell_type":"code","source":"!tar -czf data.tar.gz /kaggle/working/vocabularies","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:43:25.123737Z","iopub.execute_input":"2023-03-26T10:43:25.124858Z","iopub.status.idle":"2023-03-26T10:43:26.272645Z","shell.execute_reply.started":"2023-03-26T10:43:25.124802Z","shell.execute_reply":"2023-03-26T10:43:26.271455Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"tar: Removing leading `/' from member names\n","output_type":"stream"}]},{"cell_type":"code","source":"os.chdir(r'/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:43:34.308725Z","iopub.execute_input":"2023-03-26T10:43:34.309455Z","iopub.status.idle":"2023-03-26T10:43:34.316134Z","shell.execute_reply.started":"2023-03-26T10:43:34.309413Z","shell.execute_reply":"2023-03-26T10:43:34.314474Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'data.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2023-03-26T10:43:44.682795Z","iopub.execute_input":"2023-03-26T10:43:44.683488Z","iopub.status.idle":"2023-03-26T10:43:44.692192Z","shell.execute_reply.started":"2023-03-26T10:43:44.683452Z","shell.execute_reply":"2023-03-26T10:43:44.690865Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/data.tar.gz","text/html":"<a href='data.tar.gz' target='_blank'>data.tar.gz</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"predictor = MaskedTokenPredictorBert(\n    model, tokenizer, max_len=250, device=device, label=0, contrast_penalty=0.0, \n    confuse_bert_args=False)\neditor.predictor = predictor\n\ndef adjust_logits(logits, label=0):\n    return logits - editor.token_toxicities * 10\n\npredictor.logits_postprocessor = adjust_logits\n\ncho = EmbeddingSimilarityChooser(sim_coef=100, tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T11:28:31.389655Z","iopub.execute_input":"2023-03-26T11:28:31.390425Z","iopub.status.idle":"2023-03-26T11:28:35.899051Z","shell.execute_reply.started":"2023-03-26T11:28:31.390389Z","shell.execute_reply":"2023-03-26T11:28:35.898003Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"model_outputs = []\nfor i, sentence in enumerate(tqdm.tqdm(sentences_hard_test)):\n    out = editor.translate(sentence, prnt=False)\n    model_outputs.append(out)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T11:38:37.253649Z","iopub.execute_input":"2023-03-26T11:38:37.254109Z","iopub.status.idle":"2023-03-26T11:41:34.292852Z","shell.execute_reply.started":"2023-03-26T11:38:37.254075Z","shell.execute_reply":"2023-03-26T11:41:34.291751Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stderr","text":"100%|██████████| 1000/1000 [02:57<00:00,  5.65it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('model_outputs', 'w') as o:\n    for output in model_outputs:\n        o.write(output)","metadata":{"execution":{"iopub.status.busy":"2023-03-26T11:42:07.858137Z","iopub.execute_input":"2023-03-26T11:42:07.858514Z","iopub.status.idle":"2023-03-26T11:42:07.865905Z","shell.execute_reply.started":"2023-03-26T11:42:07.858480Z","shell.execute_reply":"2023-03-26T11:42:07.864858Z"},"trusted":true},"execution_count":130,"outputs":[]}]}