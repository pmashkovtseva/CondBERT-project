{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate --quiet","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:15:30.208079Z","iopub.execute_input":"2023-03-25T21:15:30.210607Z","iopub.status.idle":"2023-03-25T21:15:42.344050Z","shell.execute_reply.started":"2023-03-25T21:15:30.210563Z","shell.execute_reply":"2023-03-25T21:15:42.342776Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom nltk import sent_tokenize, word_tokenize\nimport random\nimport pandas as pd\nfrom datasets import Dataset, DatasetDict\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer\nimport os\nimport torch\nimport evaluate\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:14:10.508452Z","iopub.execute_input":"2023-03-25T22:14:10.509063Z","iopub.status.idle":"2023-03-25T22:14:10.517523Z","shell.execute_reply.started":"2023-03-25T22:14:10.509014Z","shell.execute_reply":"2023-03-25T22:14:10.515858Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"data = load_dataset('onestop_english')","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:16:47.852264Z","iopub.execute_input":"2023-03-25T21:16:47.852991Z","iopub.status.idle":"2023-03-25T21:16:49.736529Z","shell.execute_reply.started":"2023-03-25T21:16:47.852950Z","shell.execute_reply":"2023-03-25T21:16:49.735379Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b3959da578747c79ed608102591614f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"385a9954920e4a16820970f92bd755a7"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset onestop_english/default (download: 1.17 MiB, generated: 2.17 MiB, post-processed: Unknown size, total: 3.34 MiB) to /root/.cache/huggingface/datasets/onestop_english/default/1.1.0/6b19eec5680862ad1cf1990e98b06a98d1fa4c85f3585dc4dfab93f52b89d9cf...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e406721ca8d540989af1bb4023891576"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/567 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset onestop_english downloaded and prepared to /root/.cache/huggingface/datasets/onestop_english/default/1.1.0/6b19eec5680862ad1cf1990e98b06a98d1fa4c85f3585dc4dfab93f52b89d9cf. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6501b258a7ec47aa8384173acd196770"}},"metadata":{}}]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:16:52.964643Z","iopub.execute_input":"2023-03-25T21:16:52.965734Z","iopub.status.idle":"2023-03-25T21:16:52.976227Z","shell.execute_reply.started":"2023-03-25T21:16:52.965684Z","shell.execute_reply":"2023-03-25T21:16:52.974627Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 567\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"sentences_hard = []\nsentences_simple = []\nfor i in range(len(data['train'])):\n    if data['train'][i]['label'] == 2:\n        for sentence in sent_tokenize(data['train'][i]['text']):\n            sentences_hard.append(' '.join(word_tokenize(sentence.lower())))\n    elif data['train'][i]['label'] == 0:\n        for sentence in sent_tokenize(data['train'][i]['text']):\n            sentences_simple.append(' '.join(word_tokenize(sentence.lower())))","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:14:12.521318Z","iopub.execute_input":"2023-03-25T22:14:12.522308Z","iopub.status.idle":"2023-03-25T22:14:14.997155Z","shell.execute_reply.started":"2023-03-25T22:14:12.522269Z","shell.execute_reply":"2023-03-25T22:14:14.995887Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"random.shuffle(sentences_hard)\nrandom.shuffle(sentences_simple)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:16:58.896401Z","iopub.execute_input":"2023-03-25T21:16:58.896938Z","iopub.status.idle":"2023-03-25T21:16:58.924133Z","shell.execute_reply.started":"2023-03-25T21:16:58.896886Z","shell.execute_reply":"2023-03-25T21:16:58.922946Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"sentences_hard_train = sentences_hard[1001:len(sentences_hard)]\nsentences_hard_test = sentences_hard[0:1000]\n\nsentences_simple_train = sentences_simple[1001:len(sentences_simple)]\nsentences_simple_test = sentences_simple[0:1000]","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:14:34.235992Z","iopub.execute_input":"2023-03-25T22:14:34.237338Z","iopub.status.idle":"2023-03-25T22:14:34.244601Z","shell.execute_reply.started":"2023-03-25T22:14:34.237277Z","shell.execute_reply":"2023-03-25T22:14:34.243587Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def collect_dataset(sentences_hard, sentences_simple):\n    dataset = []\n    for sentence_hard in sentences_hard:\n        dataset.append({'text': sentence_hard, 'label': 1})\n    for sentence_simple in sentences_simple:\n        dataset.append({'text': sentence_simple, 'label': 0})\n    random.shuffle(dataset)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:17:03.701737Z","iopub.execute_input":"2023-03-25T21:17:03.703115Z","iopub.status.idle":"2023-03-25T21:17:03.709275Z","shell.execute_reply.started":"2023-03-25T21:17:03.703065Z","shell.execute_reply":"2023-03-25T21:17:03.708287Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dataset = pd.DataFrame.from_dict(collect_dataset(sentences_hard_train, sentences_simple_train))\ntest_dataset = pd.DataFrame.from_dict(collect_dataset(sentences_hard_test, sentences_simple_test))","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:14:36.480591Z","iopub.execute_input":"2023-03-25T22:14:36.481483Z","iopub.status.idle":"2023-03-25T22:14:36.532469Z","shell.execute_reply.started":"2023-03-25T22:14:36.481444Z","shell.execute_reply":"2023-03-25T22:14:36.530714Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"datasets_train_test = DatasetDict({\n    \"train\": Dataset.from_pandas(train_dataset),\n    \"test\": Dataset.from_pandas(test_dataset)\n    })","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:14:38.215152Z","iopub.execute_input":"2023-03-25T22:14:38.217111Z","iopub.status.idle":"2023-03-25T22:14:38.242538Z","shell.execute_reply.started":"2023-03-25T22:14:38.217060Z","shell.execute_reply":"2023-03-25T22:14:38.241492Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"os.environ['CUDA_VISIBLE_DEVICES'] = '0'\ndevice = torch.device('cuda:0')\ndevice = torch.device('cpu')","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:17:19.810390Z","iopub.execute_input":"2023-03-25T21:17:19.811334Z","iopub.status.idle":"2023-03-25T21:17:19.816960Z","shell.execute_reply.started":"2023-03-25T21:17:19.811270Z","shell.execute_reply":"2023-03-25T21:17:19.815807Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained('roberta-base')\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:17:22.746775Z","iopub.execute_input":"2023-03-25T21:17:22.747480Z","iopub.status.idle":"2023-03-25T21:17:31.622865Z","shell.execute_reply.started":"2023-03-25T21:17:22.747442Z","shell.execute_reply":"2023-03-25T21:17:31.621847Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83bb5026c15e44cab9c1fe34774b1681"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/501M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c280a738c7954eb89b2fa9294b35e5bf"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d634579f20cb4ed4a0ec5e0fdcc89480"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"304afa040b254054b109e7e329ede638"}},"metadata":{}}]},{"cell_type":"code","source":"model.to(device);","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:17:56.282621Z","iopub.execute_input":"2023-03-25T21:17:56.283024Z","iopub.status.idle":"2023-03-25T21:17:56.295585Z","shell.execute_reply.started":"2023-03-25T21:17:56.282988Z","shell.execute_reply":"2023-03-25T21:17:56.294206Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def tokenization(text):\n    return tokenizer(text[\"text\"], padding='max_length', truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:17:58.100478Z","iopub.execute_input":"2023-03-25T21:17:58.100891Z","iopub.status.idle":"2023-03-25T21:17:58.106928Z","shell.execute_reply.started":"2023-03-25T21:17:58.100854Z","shell.execute_reply":"2023-03-25T21:17:58.105875Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"datasets_train_test = datasets_train_test.map(tokenization, batched=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:14:49.267905Z","iopub.execute_input":"2023-03-25T22:14:49.268328Z","iopub.status.idle":"2023-03-25T22:14:54.591496Z","shell.execute_reply.started":"2023-03-25T22:14:49.268292Z","shell.execute_reply":"2023-03-25T22:14:54.587900Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/11 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e7d1a0abcc14b3da8d38cec5c1122b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f72d9c42b4c744f5a554a910e10be8fb"}},"metadata":{}}]},{"cell_type":"code","source":"datasets_train_test","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:14:58.169484Z","iopub.execute_input":"2023-03-25T22:14:58.170305Z","iopub.status.idle":"2023-03-25T22:14:58.179461Z","shell.execute_reply.started":"2023-03-25T22:14:58.170268Z","shell.execute_reply":"2023-03-25T22:14:58.178255Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 10109\n    })\n    test: Dataset({\n        features: ['text', 'label', 'input_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"datasets_train_test = datasets_train_test.class_encode_column('label')\ndatasets_train_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:15:00.062298Z","iopub.execute_input":"2023-03-25T22:15:00.062978Z","iopub.status.idle":"2023-03-25T22:15:15.157937Z","shell.execute_reply.started":"2023-03-25T22:15:00.062938Z","shell.execute_reply":"2023-03-25T22:15:15.156015Z"},"trusted":true},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"Stringifying the column:   0%|          | 0/11 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcee51acf73649e18751d8b30886a48b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/11 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"887391b190194bdabcd1308cbf86d20e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19e0c8fdd17544759eb803017f2093ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Stringifying the column:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6c317995900450ab4684487d51b7e9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting to class labels:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e6abbc576a9406db82d1bda02d1c330"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae0476700d5f4583b43ff44b1facef4f"}},"metadata":{}}]},{"cell_type":"code","source":"clf_metrics = evaluate.combine([\"accuracy\"])\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return clf_metrics.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:20:17.821244Z","iopub.execute_input":"2023-03-25T21:20:17.821615Z","iopub.status.idle":"2023-03-25T21:20:18.291245Z","shell.execute_reply.started":"2023-03-25T21:20:17.821581Z","shell.execute_reply":"2023-03-25T21:20:18.290114Z"},"trusted":true},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09883a543257464f9ac27356ddecb2cc"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='results',\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    num_train_epochs=2,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=32,\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    warmup_steps=10\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:15:15.162413Z","iopub.execute_input":"2023-03-25T22:15:15.166450Z","iopub.status.idle":"2023-03-25T22:15:15.184756Z","shell.execute_reply.started":"2023-03-25T22:15:15.166420Z","shell.execute_reply":"2023-03-25T22:15:15.183774Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=datasets_train_test['train'],\n    eval_dataset=datasets_train_test['test'],\n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:15:17.353504Z","iopub.execute_input":"2023-03-25T22:15:17.354481Z","iopub.status.idle":"2023-03-25T22:15:17.377110Z","shell.execute_reply.started":"2023-03-25T22:15:17.354442Z","shell.execute_reply":"2023-03-25T22:15:17.375747Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2023-03-25T21:20:43.468661Z","iopub.execute_input":"2023-03-25T21:20:43.469045Z","iopub.status.idle":"2023-03-25T21:20:43.474047Z","shell.execute_reply.started":"2023-03-25T21:20:43.469011Z","shell.execute_reply":"2023-03-25T21:20:43.472971Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-03-25T22:15:19.708587Z","iopub.execute_input":"2023-03-25T22:15:19.709085Z","iopub.status.idle":"2023-03-25T22:46:51.360278Z","shell.execute_reply.started":"2023-03-25T22:15:19.709037Z","shell.execute_reply":"2023-03-25T22:46:51.358918Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 10109\n  Num Epochs = 2\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 1\n  Total optimization steps = 1264\n  Number of trainable parameters = 124647170\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1264' max='1264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1264/1264 31:30, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.504100</td>\n      <td>0.454365</td>\n      <td>0.810500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.450600</td>\n      <td>0.385208</td>\n      <td>0.834000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 2000\n  Batch size = 32\nSaving model checkpoint to results/checkpoint-632\nConfiguration saved in results/checkpoint-632/config.json\nModel weights saved in results/checkpoint-632/pytorch_model.bin\nThe following columns in the evaluation set don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text. If text are not expected by `RobertaForSequenceClassification.forward`,  you can safely ignore this message.\n***** Running Evaluation *****\n  Num examples = 2000\n  Batch size = 32\nSaving model checkpoint to results/checkpoint-1264\nConfiguration saved in results/checkpoint-1264/config.json\nModel weights saved in results/checkpoint-1264/pytorch_model.bin\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from results/checkpoint-1264 (score: 0.3852078318595886).\n","output_type":"stream"},{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1264, training_loss=0.4576151702977434, metrics={'train_runtime': 1891.6068, 'train_samples_per_second': 10.688, 'train_steps_per_second': 0.668, 'total_flos': 5319579317268480.0, 'train_loss': 0.4576151702977434, 'epoch': 2.0})"},"metadata":{}}]}]}